{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc685d67",
   "metadata": {},
   "source": [
    "# Pandas Introduction\n",
    "\n",
    "Pandas is a powerful library for data manipulation and analysis in Python. It provides data structures like Series and DataFrame for handling structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21b4cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas imported successfully!\n",
      "Pandas version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Pandas imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f8e45",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "A Series is a one-dimensional labeled array that can hold any data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af031785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    6\n",
      "4    8\n",
      "dtype: int64\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "Series with custom index:\n",
      "a    10\n",
      "b    20\n",
      "c    30\n",
      "dtype: int64\n",
      "s[0]: 1\n",
      "s_custom['b']: 20\n",
      "Mean: 4.6\n",
      "Sum: 23\n",
      "Max: 8\n"
     ]
    }
   ],
   "source": [
    "# Creating a Series\n",
    "s = pd.Series([1, 3, 5, 6, 8])\n",
    "print(\"Series:\")\n",
    "print(s)\n",
    "print(f\"Type: {type(s)}\")\n",
    "\n",
    "# Series with custom index\n",
    "s_custom = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "print(\"\\nSeries with custom index:\")\n",
    "print(s_custom)\n",
    "\n",
    "# Accessing elements\n",
    "print(f\"s[0]: {s[0]}\")\n",
    "print(f\"s_custom['b']: {s_custom['b']}\")\n",
    "\n",
    "# Basic operations\n",
    "print(f\"Mean: {s.mean()}\")\n",
    "print(f\"Sum: {s.sum()}\")\n",
    "print(f\"Max: {s.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2f8ae",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "A DataFrame is a two-dimensional labeled data structure with columns of potentially different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a0bc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "      Name  Age     City\n",
      "0    Alice   25      NYC\n",
      "1      Bob   30       LA\n",
      "2  Charlie   35  Chicago\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Shape: (3, 3)\n",
      "Columns: ['Name', 'Age', 'City']\n",
      "Index: [0, 1, 2]\n",
      "\n",
      "Names: ['Alice', 'Bob', 'Charlie']\n",
      "Ages: [25, 30, 35]\n",
      "\n",
      "First row:\n",
      "Name    Alice\n",
      "Age        25\n",
      "City      NYC\n",
      "Name: 0, dtype: object\n",
      "Row with index 1:\n",
      "Name    Bob\n",
      "Age      30\n",
      "City     LA\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Age statistics:\n",
      "count     3.0\n",
      "mean     30.0\n",
      "std       5.0\n",
      "min      25.0\n",
      "25%      27.5\n",
      "50%      30.0\n",
      "75%      32.5\n",
      "max      35.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame from dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['NYC', 'LA', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(f\"Type: {type(df)}\")\n",
    "\n",
    "# Basic info\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Index: {list(df.index)}\")\n",
    "\n",
    "# Accessing columns\n",
    "print(f\"\\nNames: {df['Name'].tolist()}\")\n",
    "print(f\"Ages: {df['Age'].tolist()}\")\n",
    "\n",
    "# Accessing rows\n",
    "print(f\"\\nFirst row:\\n{df.iloc[0]}\")\n",
    "print(f\"Row with index 1:\\n{df.loc[1]}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nAge statistics:\\n{df['Age'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c9036",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "Pandas can read data from various file formats like CSV, Excel, JSON, and SQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e80f23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from CSV:\n",
      "      name  age         city  salary\n",
      "0    Alice   25     New York   50000\n",
      "1      Bob   30  Los Angeles   60000\n",
      "2  Charlie   35      Chicago   70000\n",
      "3    Diana   28      Houston   55000\n",
      "4      Eve   32      Phoenix   65000\n",
      "\n",
      "Data types:\n",
      "name      object\n",
      "age        int64\n",
      "city      object\n",
      "salary     int64\n",
      "dtype: object\n",
      "\n",
      "CSV with custom index:\n",
      "         age         city  salary\n",
      "name                             \n",
      "Alice     25     New York   50000\n",
      "Bob       30  Los Angeles   60000\n",
      "Charlie   35      Chicago   70000\n",
      "Diana     28      Houston   55000\n",
      "Eve       32      Phoenix   65000\n",
      "\n",
      "Data from JSON:\n",
      "    name  age city\n",
      "0  Alice   25  NYC\n",
      "1    Bob   30   LA\n"
     ]
    }
   ],
   "source": [
    "# Reading CSV file\n",
    "df_csv = pd.read_csv('../data/sample_data.csv')\n",
    "print(\"Data from CSV:\")\n",
    "print(df_csv)\n",
    "print(f\"\\nData types:\\n{df_csv.dtypes}\")\n",
    "\n",
    "# Reading with options\n",
    "df_csv_custom = pd.read_csv('../data/sample_data.csv', index_col=0)\n",
    "print(\"\\nCSV with custom index:\")\n",
    "print(df_csv_custom)\n",
    "\n",
    "# Creating sample JSON data\n",
    "import json\n",
    "sample_data = [\n",
    "    {\"name\": \"Alice\", \"age\": 25, \"city\": \"NYC\"},\n",
    "    {\"name\": \"Bob\", \"age\": 30, \"city\": \"LA\"}\n",
    "]\n",
    "with open('../data/sample.json', 'w') as f:\n",
    "    json.dump(sample_data, f)\n",
    "\n",
    "# Reading JSON\n",
    "df_json = pd.read_json('../data/sample.json')\n",
    "print(\"\\nData from JSON:\")\n",
    "print(df_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff1f05",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Data cleaning involves handling missing values, duplicates, and data type conversions to prepare data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17233e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name   Age   Salary\n",
      "0    Alice  25.0  50000.0\n",
      "1      Bob   NaN  60000.0\n",
      "2  Charlie  35.0      NaN\n",
      "3    Alice  25.0  50000.0\n",
      "4      Eve  32.0  65000.0\n",
      "\n",
      "Missing values:\n",
      "Name      0\n",
      "Age       1\n",
      "Salary    1\n",
      "dtype: int64\n",
      "\n",
      "DataFrame after filling missing values:\n",
      "      Name    Age   Salary\n",
      "0    Alice  25.00  50000.0\n",
      "1      Bob  29.25  60000.0\n",
      "2  Charlie  35.00  55000.0\n",
      "3    Alice  25.00  50000.0\n",
      "4      Eve  32.00  65000.0\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "      Name    Age   Salary\n",
      "0    Alice  25.00  50000.0\n",
      "1      Bob  29.25  60000.0\n",
      "2  Charlie  35.00  55000.0\n",
      "4      Eve  32.00  65000.0\n",
      "\n",
      "DataFrame with Age as int:\n",
      "      Name  Age   Salary\n",
      "0    Alice   25  50000.0\n",
      "1      Bob   29  60000.0\n",
      "2  Charlie   35  55000.0\n",
      "4      Eve   32  65000.0\n",
      "\n",
      "Data types:\n",
      "Name       object\n",
      "Age         int64\n",
      "Salary    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/sh_trgw128d534fn5tl4mw5r0000gn/T/ipykernel_62644/3725217668.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_duplicates['Age'] = df_no_duplicates['Age'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning Examples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values and duplicates\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve'],\n",
    "    'Age': [25, np.nan, 35, 25, 32],\n",
    "    'Salary': [50000, 60000, np.nan, 50000, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Fill missing values\n",
    "df_filled = df.fillna({'Age': df['Age'].mean(), 'Salary': df['Salary'].median()})\n",
    "print(\"\\nDataFrame after filling missing values:\")\n",
    "print(df_filled)\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_duplicates = df_filled.drop_duplicates()\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_no_duplicates)\n",
    "\n",
    "# Convert data types if needed\n",
    "df_no_duplicates['Age'] = df_no_duplicates['Age'].astype(int)\n",
    "print(\"\\nDataFrame with Age as int:\")\n",
    "print(df_no_duplicates)\n",
    "print(f\"\\nData types:\\n{df_no_duplicates.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b0902",
   "metadata": {},
   "source": [
    "## Data Filtering and Selection\n",
    "\n",
    "Pandas provides powerful tools for filtering and selecting data using boolean indexing, loc, and iloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf6c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      name  age         city  salary\n",
      "0    Alice   25     New York   50000\n",
      "1      Bob   30  Los Angeles   60000\n",
      "2  Charlie   35      Chicago   70000\n",
      "3    Diana   28      Houston   55000\n",
      "4      Eve   32      Phoenix   65000\n",
      "\n",
      "Employees with salary > 60000:\n",
      "      name  age     city  salary\n",
      "2  Charlie   35  Chicago   70000\n",
      "4      Eve   32  Phoenix   65000\n",
      "\n",
      "Employees in New York or Los Angeles:\n",
      "    name  age         city  salary\n",
      "0  Alice   25     New York   50000\n",
      "1    Bob   30  Los Angeles   60000\n",
      "\n",
      "Using loc - rows 1 to 3, columns 'name' and 'salary':\n",
      "      name  salary\n",
      "1      Bob   60000\n",
      "2  Charlie   70000\n",
      "3    Diana   55000\n",
      "\n",
      "Using iloc - first 3 rows, first 2 columns:\n",
      "      name  age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "\n",
      "Names and ages:\n",
      "      name  age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "3    Diana   28\n",
      "4      Eve   32\n",
      "\n",
      "Sorted by age:\n",
      "      name  age         city  salary\n",
      "0    Alice   25     New York   50000\n",
      "3    Diana   28      Houston   55000\n",
      "1      Bob   30  Los Angeles   60000\n",
      "4      Eve   32      Phoenix   65000\n",
      "2  Charlie   35      Chicago   70000\n"
     ]
    }
   ],
   "source": [
    "# Data Filtering and Selection Examples\n",
    "import pandas as pd\n",
    "\n",
    "# Using the sample data\n",
    "df = pd.read_csv('../data/sample_data.csv')\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Boolean indexing - filter by condition\n",
    "high_salary = df[df['salary'] > 60000]\n",
    "print(\"\\nEmployees with salary > 60000:\")\n",
    "print(high_salary)\n",
    "\n",
    "# Multiple conditions\n",
    "ny_or_la = df[(df['city'] == 'New York') | (df['city'] == 'Los Angeles')]\n",
    "print(\"\\nEmployees in New York or Los Angeles:\")\n",
    "print(ny_or_la)\n",
    "\n",
    "# Using loc for label-based selection\n",
    "print(\"\\nUsing loc - rows 1 to 3, columns 'name' and 'salary':\")\n",
    "print(df.loc[1:3, ['name', 'salary']])\n",
    "\n",
    "# Using iloc for integer-based selection\n",
    "print(\"\\nUsing iloc - first 3 rows, first 2 columns:\")\n",
    "print(df.iloc[:3, :2])\n",
    "\n",
    "# Selecting specific columns\n",
    "names_and_ages = df[['name', 'age']]\n",
    "print(\"\\nNames and ages:\")\n",
    "print(names_and_ages)\n",
    "\n",
    "# Sorting data\n",
    "sorted_by_age = df.sort_values('age')\n",
    "print(\"\\nSorted by age:\")\n",
    "print(sorted_by_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d41300",
   "metadata": {},
   "source": [
    "## Grouping and Aggregation\n",
    "\n",
    "Grouping data allows you to split data into groups based on criteria and apply aggregate functions like sum, mean, count, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d814bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "  Department Employee  Salary  Years\n",
      "0         HR    Alice   50000      2\n",
      "1         IT      Bob   60000      5\n",
      "2         HR  Charlie   55000      3\n",
      "3         IT    Diana   65000      4\n",
      "4    Finance      Eve   70000      6\n",
      "5    Finance    Frank   75000      7\n",
      "6         IT    Grace   62000      3\n",
      "\n",
      "Average salary by department:\n",
      "Department\n",
      "Finance    72500.000000\n",
      "HR         52500.000000\n",
      "IT         62333.333333\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "Multiple aggregations by department:\n",
      "                  Salary               Years\n",
      "                    mean     sum count  mean\n",
      "Department                                  \n",
      "Finance     72500.000000  145000     2   6.5\n",
      "HR          52500.000000  105000     2   2.5\n",
      "IT          62333.333333  187000     3   4.0\n",
      "\n",
      "Average salary by department and seniority:\n",
      "Department  Seniority\n",
      "Finance     Senior       72500.0\n",
      "HR          Junior       52500.0\n",
      "IT          Junior       63500.0\n",
      "            Senior       60000.0\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "DataFrame with department average salary:\n",
      "  Employee Department  Salary  Dept_Avg_Salary\n",
      "0    Alice         HR   50000     52500.000000\n",
      "1      Bob         IT   60000     62333.333333\n",
      "2  Charlie         HR   55000     52500.000000\n",
      "3    Diana         IT   65000     62333.333333\n",
      "4      Eve    Finance   70000     72500.000000\n",
      "5    Frank    Finance   75000     72500.000000\n",
      "6    Grace         IT   62000     62333.333333\n"
     ]
    }
   ],
   "source": [
    "# Grouping and Aggregation Examples\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame for grouping\n",
    "data = {\n",
    "    'Department': ['HR', 'IT', 'HR', 'IT', 'Finance', 'Finance', 'IT'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace'],\n",
    "    'Salary': [50000, 60000, 55000, 65000, 70000, 75000, 62000],\n",
    "    'Years': [2, 5, 3, 4, 6, 7, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by Department and calculate mean salary\n",
    "grouped = df.groupby('Department')['Salary'].mean()\n",
    "print(\"\\nAverage salary by department:\")\n",
    "print(grouped)\n",
    "\n",
    "# Multiple aggregations\n",
    "agg_result = df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'sum', 'count'],\n",
    "    'Years': 'mean'\n",
    "})\n",
    "print(\"\\nMultiple aggregations by department:\")\n",
    "print(agg_result)\n",
    "\n",
    "# Group by multiple columns\n",
    "df['Seniority'] = df['Years'].apply(lambda x: 'Senior' if x > 4 else 'Junior')\n",
    "grouped_multi = df.groupby(['Department', 'Seniority'])['Salary'].mean()\n",
    "print(\"\\nAverage salary by department and seniority:\")\n",
    "print(grouped_multi)\n",
    "\n",
    "# Using transform to add group statistics\n",
    "df['Dept_Avg_Salary'] = df.groupby('Department')['Salary'].transform('mean')\n",
    "print(\"\\nDataFrame with department average salary:\")\n",
    "print(df[['Employee', 'Department', 'Salary', 'Dept_Avg_Salary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90396db",
   "metadata": {},
   "source": [
    "## Merging and Joining DataFrames\n",
    "\n",
    "Pandas provides methods to combine DataFrames using merge, join, and concatenate operations, similar to SQL joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999edda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees DataFrame:\n",
      "   EmployeeID     Name  DepartmentID\n",
      "0           1    Alice           101\n",
      "1           2      Bob           102\n",
      "2           3  Charlie           101\n",
      "3           4    Diana           103\n",
      "\n",
      "Departments DataFrame:\n",
      "   DepartmentID DepartmentName Location\n",
      "0           101             HR      NYC\n",
      "1           102             IT       LA\n",
      "2           103        Finance  Chicago\n",
      "3           104      Marketing   Boston\n",
      "\n",
      "Salaries DataFrame:\n",
      "   EmployeeID  Salary  Bonus\n",
      "0           1   50000   5000\n",
      "1           2   60000   6000\n",
      "2           3   55000   5500\n",
      "3           5   70000   7000\n",
      "\n",
      "Inner join on DepartmentID:\n",
      "   EmployeeID     Name  DepartmentID DepartmentName Location\n",
      "0           1    Alice           101             HR      NYC\n",
      "1           2      Bob           102             IT       LA\n",
      "2           3  Charlie           101             HR      NYC\n",
      "3           4    Diana           103        Finance  Chicago\n",
      "\n",
      "Left join on EmployeeID:\n",
      "   EmployeeID     Name  DepartmentID   Salary   Bonus\n",
      "0           1    Alice           101  50000.0  5000.0\n",
      "1           2      Bob           102  60000.0  6000.0\n",
      "2           3  Charlie           101  55000.0  5500.0\n",
      "3           4    Diana           103      NaN     NaN\n",
      "\n",
      "Outer join on EmployeeID:\n",
      "   EmployeeID     Name  DepartmentID   Salary   Bonus\n",
      "0           1    Alice         101.0  50000.0  5000.0\n",
      "1           2      Bob         102.0  60000.0  6000.0\n",
      "2           3  Charlie         101.0  55000.0  5500.0\n",
      "3           4    Diana         103.0      NaN     NaN\n",
      "4           5      NaN           NaN  70000.0  7000.0\n",
      "\n",
      "Concatenated DataFrames:\n",
      "   EmployeeID     Name  DepartmentID\n",
      "0           1    Alice           101\n",
      "1           2      Bob           102\n",
      "2           3  Charlie           101\n",
      "3           4    Diana           103\n",
      "4           5      Eve           104\n",
      "5           6    Frank           102\n",
      "\n",
      "Full employee information (multiple merges):\n",
      "   EmployeeID     Name  DepartmentID DepartmentName Location   Salary   Bonus\n",
      "0           1    Alice           101             HR      NYC  50000.0  5000.0\n",
      "1           2      Bob           102             IT       LA  60000.0  6000.0\n",
      "2           3  Charlie           101             HR      NYC  55000.0  5500.0\n",
      "3           4    Diana           103        Finance  Chicago      NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# Merging and Joining Examples\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrames\n",
    "employees = pd.DataFrame({\n",
    "    'EmployeeID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'DepartmentID': [101, 102, 101, 103]\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'DepartmentID': [101, 102, 103, 104],\n",
    "    'DepartmentName': ['HR', 'IT', 'Finance', 'Marketing'],\n",
    "    'Location': ['NYC', 'LA', 'Chicago', 'Boston']\n",
    "})\n",
    "\n",
    "salaries = pd.DataFrame({\n",
    "    'EmployeeID': [1, 2, 3, 5],\n",
    "    'Salary': [50000, 60000, 55000, 70000],\n",
    "    'Bonus': [5000, 6000, 5500, 7000]\n",
    "})\n",
    "\n",
    "print(\"Employees DataFrame:\")\n",
    "print(employees)\n",
    "print(\"\\nDepartments DataFrame:\")\n",
    "print(departments)\n",
    "print(\"\\nSalaries DataFrame:\")\n",
    "print(salaries)\n",
    "\n",
    "# Inner join (default)\n",
    "merged_inner = pd.merge(employees, departments, on='DepartmentID', how='inner')\n",
    "print(\"\\nInner join on DepartmentID:\")\n",
    "print(merged_inner)\n",
    "\n",
    "# Left join\n",
    "merged_left = pd.merge(employees, salaries, on='EmployeeID', how='left')\n",
    "print(\"\\nLeft join on EmployeeID:\")\n",
    "print(merged_left)\n",
    "\n",
    "# Outer join\n",
    "merged_outer = pd.merge(employees, salaries, on='EmployeeID', how='outer')\n",
    "print(\"\\nOuter join on EmployeeID:\")\n",
    "print(merged_outer)\n",
    "\n",
    "# Concatenate DataFrames vertically\n",
    "additional_employees = pd.DataFrame({\n",
    "    'EmployeeID': [5, 6],\n",
    "    'Name': ['Eve', 'Frank'],\n",
    "    'DepartmentID': [104, 102]\n",
    "})\n",
    "\n",
    "concatenated = pd.concat([employees, additional_employees], ignore_index=True)\n",
    "print(\"\\nConcatenated DataFrames:\")\n",
    "print(concatenated)\n",
    "\n",
    "# Multiple merges\n",
    "full_info = pd.merge(pd.merge(employees, departments, on='DepartmentID'), salaries, on='EmployeeID', how='left')\n",
    "print(\"\\nFull employee information (multiple merges):\")\n",
    "print(full_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c06cd5",
   "metadata": {},
   "source": [
    "## Pivot Tables and Cross-tabulations\n",
    "\n",
    "Pivot tables allow you to reshape and summarize data, while cross-tabulations provide frequency distributions across categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bb9bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sales DataFrame:\n",
      "        Date Product Region  Sales  Quantity\n",
      "0 2023-01-01       B   West    383         2\n",
      "1 2023-01-02       A  South    852         9\n",
      "2 2023-01-03       B   East    968         1\n",
      "3 2023-01-04       C  North    713         5\n",
      "4 2023-01-05       B  South    738         1\n",
      "5 2023-01-06       A   East    451         5\n",
      "6 2023-01-07       A  South    255         9\n",
      "7 2023-01-08       C  North    299         2\n",
      "8 2023-01-09       C   West    415         9\n",
      "9 2023-01-10       C  South    854         6\n",
      "\n",
      "Pivot table - Total sales by Product and Region:\n",
      "Region     East   North   South    West\n",
      "Product                                \n",
      "A         451.0   739.0  1758.0     NaN\n",
      "B        1122.0   803.0  1969.0  1601.0\n",
      "C         858.0  1012.0   854.0  1226.0\n",
      "\n",
      "Pivot table - Multiple aggregations:\n",
      "            sum                           mean                                 \\\n",
      "Region     East   North   South    West   East  North       South        West   \n",
      "Product                                                                         \n",
      "A         451.0   739.0  1758.0     NaN  451.0  739.0  586.000000         NaN   \n",
      "B        1122.0   803.0  1969.0  1601.0  561.0  803.0  656.333333  533.666667   \n",
      "C         858.0  1012.0   854.0  1226.0  858.0  506.0  854.000000  613.000000   \n",
      "\n",
      "        count                   \n",
      "Region   East North South West  \n",
      "Product                         \n",
      "A         1.0   1.0   3.0  NaN  \n",
      "B         2.0   1.0   3.0  3.0  \n",
      "C         1.0   2.0   1.0  2.0  \n",
      "\n",
      "Pivot table with totals:\n",
      "Region     East   North   South    West  Total\n",
      "Product                                       \n",
      "A         451.0   739.0  1758.0     NaN   2948\n",
      "B        1122.0   803.0  1969.0  1601.0   5495\n",
      "C         858.0  1012.0   854.0  1226.0   3950\n",
      "Total    2431.0  2554.0  4581.0  2827.0  12393\n",
      "\n",
      "Cross-tabulation - Product vs Region frequency:\n",
      "Region   East  North  South  West\n",
      "Product                          \n",
      "A           1      1      3     0\n",
      "B           2      1      3     3\n",
      "C           1      2      1     2\n",
      "\n",
      "Cross-tabulation with average sales:\n",
      "Region    East  North       South        West\n",
      "Product                                      \n",
      "A        451.0  739.0  586.000000         NaN\n",
      "B        561.0  803.0  656.333333  533.666667\n",
      "C        858.0  506.0  854.000000  613.000000\n",
      "\n",
      "Monthly sales pivot table:\n",
      "Month       1\n",
      "Product      \n",
      "A        2948\n",
      "B        5495\n",
      "C        3950\n"
     ]
    }
   ],
   "source": [
    "# Pivot Tables and Cross-tabulations Examples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample sales data\n",
    "sales_data = {\n",
    "    'Date': pd.date_range('2023-01-01', periods=20, freq='D'),\n",
    "    'Product': np.random.choice(['A', 'B', 'C'], 20),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], 20),\n",
    "    'Sales': np.random.randint(100, 1000, 20),\n",
    "    'Quantity': np.random.randint(1, 10, 20)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sales_data)\n",
    "print(\"Sample sales DataFrame:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Basic pivot table\n",
    "pivot_basic = pd.pivot_table(df, values='Sales', index='Product', columns='Region', aggfunc='sum')\n",
    "print(\"\\nPivot table - Total sales by Product and Region:\")\n",
    "print(pivot_basic)\n",
    "\n",
    "# Pivot table with multiple aggregation functions\n",
    "pivot_multi = pd.pivot_table(df, values='Sales', index='Product', columns='Region',\n",
    "                           aggfunc=['sum', 'mean', 'count'])\n",
    "print(\"\\nPivot table - Multiple aggregations:\")\n",
    "print(pivot_multi)\n",
    "\n",
    "# Pivot table with margins (totals)\n",
    "pivot_margins = pd.pivot_table(df, values='Sales', index='Product', columns='Region',\n",
    "                             aggfunc='sum', margins=True, margins_name='Total')\n",
    "print(\"\\nPivot table with totals:\")\n",
    "print(pivot_margins)\n",
    "\n",
    "# Cross-tabulation\n",
    "crosstab = pd.crosstab(df['Product'], df['Region'])\n",
    "print(\"\\nCross-tabulation - Product vs Region frequency:\")\n",
    "print(crosstab)\n",
    "\n",
    "# Cross-tabulation with values\n",
    "crosstab_values = pd.crosstab(df['Product'], df['Region'], values=df['Sales'], aggfunc='mean')\n",
    "print(\"\\nCross-tabulation with average sales:\")\n",
    "print(crosstab_values)\n",
    "\n",
    "# Pivot table with date grouping (monthly)\n",
    "df['Month'] = df['Date'].dt.month\n",
    "pivot_monthly = pd.pivot_table(df, values='Sales', index='Product', columns='Month', aggfunc='sum')\n",
    "print(\"\\nMonthly sales pivot table:\")\n",
    "print(pivot_monthly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
